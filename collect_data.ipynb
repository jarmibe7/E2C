{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "# os.environ[\"DISPLAY\"] = \"99\"\n",
    "rand_seed=123\n",
    "device = torch.device(f\"cuda:{2}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f47c6b95550>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp = Display(visible=0, size=(480, 480))\n",
    "disp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jarmibe7/E2C/venv/lib/python3.8/site-packages/glfw/__init__.py:917: GLFWError: (65550) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "/home/jarmibe7/E2C/venv/lib/python3.8/site-packages/glfw/__init__.py:917: GLFWError: (65537) b'The GLFW library is not initialized'\n",
      "  warnings.warn(message, GLFWError)\n"
     ]
    },
    {
     "ename": "FatalError",
     "evalue": "an OpenGL platform library has not been loaded into this process, this most likely means that a valid OpenGL context has not been created before mjr_makeContext was called",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFatalError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obs_counter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# if obs_counter + 3 >= data_length:\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(next_imgs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 18\u001b[0m         rendered_img \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;66;03m# rendered_img = rendered_img[:, 50:-50, :] # Acrobot\u001b[39;00m\n\u001b[1;32m     20\u001b[0m         rendered_img \u001b[38;5;241m=\u001b[39m rendered_img[\u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m100\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, :]\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/core.py:337\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/wrappers/common.py:409\u001b[0m, in \u001b[0;36mOrderEnforcing.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_disable_render_order_enforcing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call `env.render()` before calling `env.reset()`, if this is an intended action, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mset `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m     )\n\u001b[0;32m--> 409\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/core.py:337\u001b[0m, in \u001b[0;36mWrapper.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RenderFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mlist\u001b[39m[RenderFrame] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`render` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/wrappers/common.py:301\u001b[0m, in \u001b[0;36mPassiveEnvChecker.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_render \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_render_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:361\u001b[0m, in \u001b[0;36menv_render_passive_checker\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01min\u001b[39;00m render_modes, (\n\u001b[1;32m    357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe environment was initialized successfully however with an unsupported render mode. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    358\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRender mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, modes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrender_modes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    359\u001b[0m         )\n\u001b[0;32m--> 361\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    363\u001b[0m     _check_render_return(env\u001b[38;5;241m.\u001b[39mrender_mode, result)\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/envs/mujoco/mujoco_env.py:159\u001b[0m, in \u001b[0;36mMujocoEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrender\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    156\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Render a frame from the MuJoCo simulation as specified by the render_mode.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmujoco_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:731\u001b[0m, in \u001b[0;36mMujocoRenderer.render\u001b[0;34m(self, render_mode)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    728\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    729\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe width: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and height: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be `None` when the render_mode is not `human`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 731\u001b[0m viewer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_viewer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrender_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrender_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m render_mode \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth_array\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgbd_tuple\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m viewer\u001b[38;5;241m.\u001b[39mrender(render_mode\u001b[38;5;241m=\u001b[39mrender_mode, camera_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcamera_id)\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:755\u001b[0m, in \u001b[0;36mMujocoRenderer._get_viewer\u001b[0;34m(self, render_mode)\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;241m=\u001b[39m WindowViewer(\n\u001b[1;32m    747\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    748\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vopt,\n\u001b[1;32m    753\u001b[0m     )\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m render_mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdepth_array\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgbd_tuple\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m--> 755\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mviewer \u001b[38;5;241m=\u001b[39m \u001b[43mOffScreenViewer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_geom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    761\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_vopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m    765\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrender_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, expected modes: human, rgb_array, depth_array, or rgbd_tuple\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    766\u001b[0m     )\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:157\u001b[0m, in \u001b[0;36mOffScreenViewer.__init__\u001b[0;34m(self, model, data, width, height, max_geom, visual_options)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    147\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmujoco.MjMujoco\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m ):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;66;03m# We must make GLContext before MjrContext\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_opengl_backend(width, height)\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_geom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvisual_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_camera()\n",
      "File \u001b[0;32m~/E2C/venv/lib/python3.8/site-packages/gymnasium/envs/mujoco/mujoco_rendering.py:69\u001b[0m, in \u001b[0;36mBaseRender.__init__\u001b[0;34m(self, model, data, width, height, max_geom, visual_options)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_context_current()\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m# Keep in Mujoco Context\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon \u001b[38;5;241m=\u001b[39m \u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMjrContext\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmujoco\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjtFontScale\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmjFONTSCALE_150\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_mujoco_buffer()\n",
      "\u001b[0;31mFatalError\u001b[0m: an OpenGL platform library has not been loaded into this process, this most likely means that a valid OpenGL context has not been created before mjr_makeContext was called"
     ]
    }
   ],
   "source": [
    "env_name = \"Reacher-v5\"\n",
    "env = gym.make(env_name, render_mode=\"rgb_array\")\n",
    "\n",
    "num_prev = 3\n",
    "data_length = 1000000\n",
    "obs, _ = env.reset(seed=rand_seed)\n",
    "\n",
    "dataset = []  # List of (obs, action, image)\n",
    "next_imgs = []\n",
    "obs_arr = []\n",
    "acts_arr = []\n",
    "\n",
    "fail_counter = 0\n",
    "for obs_counter in tqdm(range(data_length)):\n",
    "    # if obs_counter + 3 >= data_length:\n",
    "    #     break\n",
    "    if len(next_imgs) == 0:\n",
    "        rendered_img = env.render()\n",
    "        # rendered_img = rendered_img[:, 50:-50, :] # Acrobot\n",
    "        rendered_img = rendered_img[100:-50, 100:-100, :]\n",
    "        img_resize = Image.fromarray(rendered_img).resize((64, 64)) #.resize((cropped.shape[1] // 8 * 8, cropped.shape[0] // 8 * 8))\n",
    "        next_imgs.append(np.asarray(img_resize))\n",
    "        obs_arr.append(obs.copy())\n",
    "\n",
    "    act = env.action_space.sample()\n",
    "    next_obs, rew, done, _, _ = env.step(act)\n",
    "    acts_arr.append(act)\n",
    "    \n",
    "    if done:\n",
    "        fail_counter += 1\n",
    "        obs, _ = env.reset()\n",
    "        next_imgs = []\n",
    "        obs_arr = []\n",
    "        acts_arr = []\n",
    "    else:\n",
    "        if len(next_imgs) == num_prev + 1:\n",
    "            obs_arr.pop(0)\n",
    "            next_imgs.pop(0)\n",
    "            acts_arr.pop(0)\n",
    "        next_img = env.render()\n",
    "        # next_img = next_img[:, 50:-50, :] # [y dir, x dir, color]\n",
    "        next_img = next_img[100:-50, 100:-100, :] # [y dir, x dir, color]\n",
    "        next_img = Image.fromarray(next_img).resize((64, 64)) #.resize((cropped.shape[1] // 8 * 8, cropped.shape[0] // 8 * 8)).resize((cropped.shape[1] // 8 * 8, cropped.shape[0] // 8 * 8))\n",
    "        next_imgs.append(np.asarray(next_img))\n",
    "        obs_arr.append(next_obs.copy())\n",
    "        \n",
    "        if len(next_imgs) == num_prev + 1:\n",
    "            \"\"\"\n",
    "            fig, ax = plt.subplots(1, 3, figsize=(8, 10))\n",
    "            ax[0].set_title(\"Current Image\")\n",
    "            ax[1].set_title(\"Current Image 2\")\n",
    "            ax[2].set_title(\"Future Image\")\n",
    "            for i, img in enumerate(next_imgs):\n",
    "                ax[i].imshow(img)\n",
    "                ax[i].set_xlabel(np.array2string(obs_arr[i], formatter={'float_kind': lambda x: \"%.2f\" % x}))\n",
    "            plt.show()\n",
    "            \"\"\"\n",
    "            # Store only valid transitions\n",
    "            dataset.append({\n",
    "                'obs': np.asarray(obs_arr).copy(),\n",
    "                'action': np.asarray(acts_arr).copy(),\n",
    "                'image': np.asarray(next_imgs[:-1]).copy(),\n",
    "                'next_image': next_imgs[-1].copy()\n",
    "            })\n",
    "        obs = next_obs\n",
    "    \n",
    "    if (obs_counter+1) % 25000 == 0 or (obs_counter+1) == data_length:\n",
    "        print(\"Saving at\", obs_counter+1)\n",
    "        all_obs = np.array([d['obs'] for d in dataset])\n",
    "        all_obs = all_obs.reshape(all_obs.shape[0], -1)\n",
    "        all_acts = np.array([d['action'] for d in dataset])\n",
    "        all_acts = all_acts.reshape(-1, all_acts.shape[-1])\n",
    "        if not os.path.exists(\"../data/\" + env_name.lower() + \"/actions.txt\"):\n",
    "            np.savetxt(\"../data/\" + env_name.lower() + \"/obs.txt\", all_obs)\n",
    "            np.savetxt(\"../data/\" + env_name.lower() + \"/actions.txt\", all_acts)\n",
    "        else:\n",
    "            prev_obs = np.loadtxt(\"../data/\" + env_name.lower() + \"/obs.txt\")\n",
    "            prev_acts = np.loadtxt(\"../data/\" + env_name.lower() + \"/actions.txt\")\n",
    "            all_obs = np.concatenate((prev_obs, all_obs), axis=0)\n",
    "            all_acts = np.concatenate((prev_acts, all_acts), axis=0)\n",
    "            np.savetxt(\"../data/\" + env_name.lower() + \"/obs.txt\", all_obs)\n",
    "            np.savetxt(\"../data/\" + env_name.lower() + \"/actions.txt\", all_acts)\n",
    "\n",
    "        # make sure to delete old images from directory before saving new ones\n",
    "        for i, d in enumerate(dataset):\n",
    "            index = i + (obs_counter+1) - 25000\n",
    "            for j, img in enumerate(d['image']):\n",
    "                Image.fromarray(img).save(f\"../data/{env_name.lower()}/{index:05d}_{j:05d}_curr.png\")\n",
    "            Image.fromarray(d['next_image']).save(f\"../data/{env_name.lower()}/{index:05d}_next.png\")\n",
    "        \n",
    "        next_imgs = []\n",
    "        obs_arr = []\n",
    "        acts_arr = []\n",
    "        dataset = []\n",
    "\n",
    "print(f\"Failures (resets): {fail_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99998/99998 [01:16<00:00, 1301.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyvirtualdisplay.display.Display at 0x7f9321502490>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_obs = np.array([d['obs'] for d in dataset])\n",
    "all_obs = all_obs.reshape(all_obs.shape[0], -1)\n",
    "# all_obs.reshape(all_obs.shape[0], num_prev+1, env.observation_space.shape[0]).shape\n",
    "np.savetxt(\"../data/\" + env_name.lower() + \"/obs.txt\", all_obs)\n",
    "all_acts = np.array([d['action'] for d in dataset])\n",
    "all_acts = all_acts.reshape(-1, all_acts.shape[-1])\n",
    "np.savetxt(\"../data/\" + env_name.lower() + \"/actions.txt\", all_acts)\n",
    "\n",
    "# make sure to delete old images from directory before saving new ones\n",
    "for i, d in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    for j, img in enumerate(d['image']):\n",
    "        Image.fromarray(img).save(f\"../data/{env_name.lower()}/{i:05d}_{j:05d}_curr.png\")\n",
    "    Image.fromarray(d['next_image']).save(f\"../data/{env_name.lower()}/{i:05d}_next.png\")\n",
    "\n",
    "disp.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2393/20000 [00:15<01:52, 156.70it/s]"
     ]
    }
   ],
   "source": [
    "env_name = \"HalfCheetah-v5\"\n",
    "env = gym.make(env_name, render_mode=\"rgb_array\")\n",
    "\n",
    "data_length = 20000\n",
    "obs, _ = env.reset(seed=rand_seed)\n",
    "\n",
    "dataset = []  # List of (obs, action, image)\n",
    "next_imgs = []\n",
    "obs_arr = []\n",
    "\n",
    "num_prev = 4\n",
    "\n",
    "fail_counter = 0\n",
    "for obs_counter in tqdm(range(data_length)):\n",
    "    # if obs_counter + 3 >= data_length:\n",
    "    #     break\n",
    "    if len(next_imgs) == 0:\n",
    "        rendered_img = env.render()\n",
    "        img_resize = Image.fromarray(rendered_img).resize((64, 64)) #.resize((cropped.shape[1] // 8 * 8, cropped.shape[0] // 8 * 8))\n",
    "        next_imgs.append(np.asarray(img_resize))\n",
    "        obs_arr.append(obs.copy())\n",
    "\n",
    "    act = env.action_space.sample()\n",
    "    next_obs, rew, done, _, _ = env.step(act)\n",
    "    \n",
    "    if done or obs_counter % 25 == 0:\n",
    "        fail_counter += 1\n",
    "        obs, _ = env.reset()\n",
    "        next_imgs = []\n",
    "        obs_arr = []\n",
    "    else:\n",
    "        if len(next_imgs) == num_prev + 1:\n",
    "            obs_arr.pop(0)\n",
    "            next_imgs.pop(0)\n",
    "        next_img = env.render()\n",
    "        next_img = Image.fromarray(next_img).resize((64, 64)) #.resize((cropped.shape[1] // 8 * 8, cropped.shape[0] // 8 * 8)).resize((cropped.shape[1] // 8 * 8, cropped.shape[0] // 8 * 8))\n",
    "        next_imgs.append(np.asarray(next_img))\n",
    "        obs_arr.append(next_obs.copy())\n",
    "        \n",
    "        if len(next_imgs) == num_prev + 1:\n",
    "            \"\"\"fig, ax = plt.subplots(1, 3, figsize=(8, 10))\n",
    "            ax[0].set_title(\"Current Image\")\n",
    "            ax[1].set_title(\"Current Image 2\")\n",
    "            ax[2].set_title(\"Future Image\")\n",
    "            for i, img in enumerate(next_imgs):\n",
    "                ax[i].imshow(img)\n",
    "                ax[i].set_xlabel(np.array2string(obs_arr[i], formatter={'float_kind': lambda x: \"%.2f\" % x}))\n",
    "            plt.show()\"\"\"\n",
    "            # Store only valid transitions\n",
    "            dataset.append({\n",
    "                'obs': np.asarray(obs_arr).copy(),\n",
    "                'action': act,\n",
    "                'image': np.asarray(next_imgs[:-1]).copy(),\n",
    "                'next_image': next_imgs[-1].copy()\n",
    "            })\n",
    "        obs = next_obs\n",
    "\n",
    "print(f\"Failures (resets): {fail_counter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19997, 5, 17)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 1699745 into shape (19999,newaxis)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m all_obs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([d[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobs\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_obs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m all_obs \u001b[38;5;241m=\u001b[39m \u001b[43mall_obs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_length\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# all_obs.reshape(data_length-1, 3, env.observation_space.shape[0]).shape\u001b[39;00m\n\u001b[1;32m      5\u001b[0m np\u001b[38;5;241m.\u001b[39msavetxt(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m env_name\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/obs.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, all_obs)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1699745 into shape (19999,newaxis)"
     ]
    }
   ],
   "source": [
    "all_obs = np.array([d['obs'] for d in dataset])\n",
    "print(all_obs.shape)\n",
    "all_obs = all_obs.reshape(all_obs.shape[0]-1, -1)\n",
    "# all_obs.reshape(data_length-1, 3, env.observation_space.shape[0]).shape\n",
    "np.savetxt(\"../data/\" + env_name.lower() + \"/obs.txt\", all_obs)\n",
    "all_acts = np.array([d['action'] for d in dataset])\n",
    "np.savetxt(\"../data/\" + env_name.lower() + \"/actions.txt\", all_acts)\n",
    "\n",
    "# make sure to delete old images from directory before saving new ones\n",
    "for i, d in tqdm(enumerate(dataset), total=len(dataset)):\n",
    "    for j, img in enumerate(d['image']):\n",
    "        Image.fromarray(img).save(f\"../data/{env_name.lower()}/{i:05d}_{j:05d}_curr.png\")\n",
    "    Image.fromarray(d['next_image']).save(f\"../data/{env_name.lower()}/{i:05d}_next.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
